{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# Загрузить библиотеки\r\n",
    "import numpy as np\r\n",
    "from keras.datasets import mnist\r\n",
    "from keras.models import Sequential\r\n",
    "from keras.layers import Dense, Dropout, Flatten\r\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\r\n",
    "from keras.utils import np_utils\r\n",
    "from keras import backend as K\r\n",
    "\r\n",
    "import tensorflow as tf\r\n",
    "import datetime"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Сделать значение цветового канала первым\r\n",
    "#K.set_image_data_format(\"channels_first\")\r\n",
    "\r\n",
    "# Задать информацию об изображении\r\n",
    "channels = 1\r\n",
    "height = 28\r\n",
    "width = 28"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Загрузить данные и цель из набора данных MNIST рукописных цифр  \r\n",
    "(data_train, target_train), (data_test, target_test) = mnist.load_data()\r\n",
    "\r\n",
    "# # Реформировать тренировочные данные об изображениях в признаки\r\n",
    "data_train = data_train.reshape(data_train.shape[0], height, width, channels)\r\n",
    "\r\n",
    "# # Реформировать тестовые данные об изображениях в признаки\r\n",
    "data_test = data_test.reshape(data_test.shape[0], height, width, channels)\r\n",
    "\r\n",
    "# Прошкалировать пиксельную интенсивность в диапазон между 0 и 1\r\n",
    "features_train = data_train / 255\r\n",
    "features_test = data_test / 255\r\n",
    "\r\n",
    "# Преобразовать цель в кодировку с одним активным состоянием\r\n",
    "target_train = np_utils.to_categorical(target_train)\r\n",
    "target_test = np_utils.to_categorical(target_test)\r\n",
    "number_of_classes = target_test.shape[1]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Инициализировать нейронную сеть\r\n",
    "network = Sequential()\r\n",
    "\r\n",
    "# Добавить сверточный слой с 64 фильтрами, окном 5x5 и \r\n",
    "# активационной функций ReLU\r\n",
    "network.add(Conv2D(filters=64,\r\n",
    "                   kernel_size=(5, 5),\r\n",
    "                   input_shape=(width, height, channels),\r\n",
    "                   activation='relu'))\r\n",
    "\r\n",
    "# Добавить максимально редуцирующий слой с окном 2x2\r\n",
    "network.add(MaxPooling2D(pool_size=(2, 2)))\r\n",
    "\r\n",
    "# Добавить отсеивающий слой\r\n",
    "network.add(Dropout(0.3))\r\n",
    "\r\n",
    "# Добавить слой для сглаживания входа\r\n",
    "network.add(Flatten())\r\n",
    "\r\n",
    "# Добавить полносвязный слой из 128 блоков с\r\n",
    "# активационной функций ReLU\r\n",
    "network.add(Dense(128, activation=\"relu\"))\r\n",
    "\r\n",
    "# Добавить отсеивающий слой\r\n",
    "network.add(Dropout(0.5))\r\n",
    "\r\n",
    "# Добавить полносвязный слой c\r\n",
    "# активационной функцией softmax\r\n",
    "network.add(Dense(number_of_classes, activation=\"softmax\"))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "#from logger import keras_metric\r\n",
    "from logger.logger import CSVLogger\r\n",
    "from logger.logger import TBLogger\r\n",
    "from logger.tf import LoggerCallback"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# CSV логгирование\r\n",
    "#logger = CSVLogger(file_path='Loss_tabl', metric_key_list=['Loss', 'Accuracy'])\r\n",
    "\r\n",
    "# Tensorboard логгирование\r\n",
    "logger = TBLogger(dir_path='TB_metric', metric_key_list =['Loss', 'Accuracy'])\r\n",
    "\r\n",
    "\r\n",
    "logger_callback = LoggerCallback(logger=logger, field_name_mapping={'Loss': 'loss', 'Accuracy': 'accuracy'})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# Скомплировать нейронную сеть\r\n",
    "network.compile(\r\n",
    "    loss=\"categorical_crossentropy\", # Перекрестная энтропия\r\n",
    "    optimizer=\"rmsprop\",  # Распространение СКО\r\n",
    "    metrics=[\"accuracy\"]) # Точностный показатель результативности\r\n",
    "\r\n",
    "# Натренировать нейронную сеть\r\n",
    "history = network.fit(\r\n",
    "    features_train,  # Признаки\r\n",
    "    target_train,    # Цель\r\n",
    "    epochs=7,        # Количество эпох\r\n",
    "    verbose=1,       # Печатать описание после каждой эпохи\r\n",
    "    batch_size=1000, # Количество наблюдений на пакет\r\n",
    "    validation_data=(features_test, target_test), # Данные для оценивания\r\n",
    "    callbacks=[logger_callback]) "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/7\n",
      " 5/60 [=>............................] - ETA: 2s - loss: 2.0638 - accuracy: 0.2445WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0036s vs `on_train_batch_end` time: 0.0295s). Check your callbacks.\n",
      "60/60 [==============================] - 5s 53ms/step - loss: 1.0054 - accuracy: 0.6716 - val_loss: 0.1770 - val_accuracy: 0.9497\n",
      "Epoch 2/7\n",
      "60/60 [==============================] - 2s 41ms/step - loss: 0.2203 - accuracy: 0.9355 - val_loss: 0.0820 - val_accuracy: 0.9739\n",
      "Epoch 3/7\n",
      "60/60 [==============================] - 2s 41ms/step - loss: 0.1295 - accuracy: 0.9617 - val_loss: 0.0580 - val_accuracy: 0.9806\n",
      "Epoch 4/7\n",
      "60/60 [==============================] - 2s 41ms/step - loss: 0.0954 - accuracy: 0.9718 - val_loss: 0.0472 - val_accuracy: 0.9834\n",
      "Epoch 5/7\n",
      "60/60 [==============================] - 2s 41ms/step - loss: 0.0782 - accuracy: 0.9764 - val_loss: 0.0401 - val_accuracy: 0.9861\n",
      "Epoch 6/7\n",
      "60/60 [==============================] - 2s 41ms/step - loss: 0.0657 - accuracy: 0.9805 - val_loss: 0.0378 - val_accuracy: 0.9867\n",
      "Epoch 7/7\n",
      "60/60 [==============================] - 2s 41ms/step - loss: 0.0596 - accuracy: 0.9819 - val_loss: 0.0354 - val_accuracy: 0.9881\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "%tensorboard --logdir='TB_metric'"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "UsageError: Line magic function `%tensorboard` not found.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bcd4279a46ae55e729019ef0bc3b545cf29015ae666f40b6f8ba7708b3cb7bc1"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}