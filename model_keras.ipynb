{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# Загрузить библиотеки\r\n",
    "import numpy as np\r\n",
    "from keras.datasets import mnist\r\n",
    "from keras.models import Sequential\r\n",
    "from keras.layers import Dense, Dropout, Flatten\r\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\r\n",
    "from keras.utils import np_utils\r\n",
    "from keras import backend as K\r\n",
    "\r\n",
    "import tensorflow as tf\r\n",
    "import datetime"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Сделать значение цветового канала первым\r\n",
    "#K.set_image_data_format(\"channels_first\")\r\n",
    "\r\n",
    "# Задать информацию об изображении\r\n",
    "channels = 1\r\n",
    "height = 28\r\n",
    "width = 28"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Загрузить данные и цель из набора данных MNIST рукописных цифр  \r\n",
    "(data_train, target_train), (data_test, target_test) = mnist.load_data()\r\n",
    "\r\n",
    "# # Реформировать тренировочные данные об изображениях в признаки\r\n",
    "data_train = data_train.reshape(data_train.shape[0], height, width, channels)\r\n",
    "\r\n",
    "# # Реформировать тестовые данные об изображениях в признаки\r\n",
    "data_test = data_test.reshape(data_test.shape[0], height, width, channels)\r\n",
    "\r\n",
    "# Прошкалировать пиксельную интенсивность в диапазон между 0 и 1\r\n",
    "features_train = data_train / 255\r\n",
    "features_test = data_test / 255\r\n",
    "\r\n",
    "# Преобразовать цель в кодировку с одним активным состоянием\r\n",
    "target_train = np_utils.to_categorical(target_train)\r\n",
    "target_test = np_utils.to_categorical(target_test)\r\n",
    "number_of_classes = target_test.shape[1]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Инициализировать нейронную сеть\r\n",
    "network = Sequential()\r\n",
    "\r\n",
    "# Добавить сверточный слой с 64 фильтрами, окном 5x5 и \r\n",
    "# активационной функций ReLU\r\n",
    "network.add(Conv2D(filters=64,\r\n",
    "                   kernel_size=(5, 5),\r\n",
    "                   input_shape=(width, height, channels),\r\n",
    "                   activation='relu'))\r\n",
    "\r\n",
    "# Добавить максимально редуцирующий слой с окном 2x2\r\n",
    "network.add(MaxPooling2D(pool_size=(2, 2)))\r\n",
    "\r\n",
    "# Добавить отсеивающий слой\r\n",
    "network.add(Dropout(0.3))\r\n",
    "\r\n",
    "# Добавить слой для сглаживания входа\r\n",
    "network.add(Flatten())\r\n",
    "\r\n",
    "# Добавить полносвязный слой из 128 блоков с\r\n",
    "# активационной функций ReLU\r\n",
    "network.add(Dense(128, activation=\"relu\"))\r\n",
    "\r\n",
    "# Добавить отсеивающий слой\r\n",
    "network.add(Dropout(0.5))\r\n",
    "\r\n",
    "# Добавить полносвязный слой c\r\n",
    "# активационной функцией softmax\r\n",
    "network.add(Dense(number_of_classes, activation=\"softmax\"))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "from logger_metric.logger import csvlogger\r\n",
    "from logger_metric.logger import tblogger\r\n",
    "\r\n",
    "from logger_metric.logger import tfcallback"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# CSV логгирование\r\n",
    "logger = csvlogger.CSVLogger(file_path='Loss_tabl', metric_key_list=['Loss', 'Accuracy'])\r\n",
    "\r\n",
    "# Tensorboard логгирование\r\n",
    "#logger = tblogger.TBLogger(dir_path='TB_metric', metric_key_list =['Loss', 'Accuracy'])\r\n",
    "\r\n",
    "\r\n",
    "logger_callback = tfcallback.LoggerCallback(logger=logger, field_name_mapping={'Loss': 'loss', 'Accuracy': 'accuracy'})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# Скомплировать нейронную сеть\r\n",
    "network.compile(\r\n",
    "    loss=\"categorical_crossentropy\", # Перекрестная энтропия\r\n",
    "    optimizer=\"rmsprop\",  # Распространение СКО\r\n",
    "    metrics=[\"accuracy\"]) # Точностный показатель результативности\r\n",
    "\r\n",
    "# Натренировать нейронную сеть\r\n",
    "history = network.fit(\r\n",
    "    features_train,  # Признаки\r\n",
    "    target_train,    # Цель\r\n",
    "    epochs=7,        # Количество эпох\r\n",
    "    verbose=1,       # Печатать описание после каждой эпохи\r\n",
    "    batch_size=1000, # Количество наблюдений на пакет\r\n",
    "    validation_data=(features_test, target_test), # Данные для оценивания\r\n",
    "    callbacks=[logger_callback]) "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/7\n",
      " 5/60 [=>............................] - ETA: 2s - loss: 2.0389 - accuracy: 0.2637WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0046s vs `on_train_batch_end` time: 0.0342s). Check your callbacks.\n",
      "60/60 [==============================] - 6s 59ms/step - loss: 0.9742 - accuracy: 0.6792 - val_loss: 0.1601 - val_accuracy: 0.9537\n",
      "Epoch 2/7\n",
      "60/60 [==============================] - 3s 47ms/step - loss: 0.2045 - accuracy: 0.9410 - val_loss: 0.0760 - val_accuracy: 0.9766\n",
      "Epoch 3/7\n",
      "60/60 [==============================] - 3s 47ms/step - loss: 0.1237 - accuracy: 0.9650 - val_loss: 0.0546 - val_accuracy: 0.9826\n",
      "Epoch 4/7\n",
      "60/60 [==============================] - 3s 47ms/step - loss: 0.0907 - accuracy: 0.9729 - val_loss: 0.0553 - val_accuracy: 0.9821\n",
      "Epoch 5/7\n",
      "60/60 [==============================] - 3s 47ms/step - loss: 0.0729 - accuracy: 0.9781 - val_loss: 0.0399 - val_accuracy: 0.9866\n",
      "Epoch 6/7\n",
      "60/60 [==============================] - 3s 47ms/step - loss: 0.0630 - accuracy: 0.9816 - val_loss: 0.0382 - val_accuracy: 0.9872\n",
      "Epoch 7/7\n",
      "60/60 [==============================] - 3s 47ms/step - loss: 0.0567 - accuracy: 0.9830 - val_loss: 0.0350 - val_accuracy: 0.9885\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "%tensorboard --logdir='TB_metric'"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "UsageError: Line magic function `%tensorboard` not found.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bcd4279a46ae55e729019ef0bc3b545cf29015ae666f40b6f8ba7708b3cb7bc1"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}